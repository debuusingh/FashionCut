{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "IMAGE_FILENAMES = ['segmentation_input_rotation0.jpg']\n",
    "\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-assets/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735057377.216500  715468 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1735057377.249323  715763 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/Users/ankityadav/Downloads/fashionHub/.venv/lib/python3.12/site-packages/mediapipe/tasks/python/vision/image_segmenter.py:158: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n",
      "  graph_config = self._runner.get_graph_config()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in segmentation_input_rotation0.jpg: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2  # For displaying images\n",
    "\n",
    "# Define distinct colors for each class (3-channel RGB)\n",
    "MASK_COLORS = [\n",
    "    (255, 0, 0),    # Red for class 0\n",
    "    (0, 255, 0),    # Green for class 1\n",
    "    (0, 0, 255),    # Blue for class 2\n",
    "    (255, 255, 0),  # Yellow for class 3\n",
    "    (255, 0, 255),  # Magenta for class 4\n",
    "    (0, 255, 255)   # Cyan for class 5\n",
    "]\n",
    "\n",
    "# Background color for areas without a class (3-channel RGB)\n",
    "BG_COLOR = (192, 192, 192)  # Gray\n",
    "\n",
    "# Create the options for the ImageSegmenter\n",
    "base_options = python.BaseOptions(model_asset_path='web_development/model/selfie_multiclass_256x256.tflite')\n",
    "options = vision.ImageSegmenterOptions(base_options=base_options,\n",
    "                                       output_category_mask=True)\n",
    "\n",
    "# Create the image segmenter\n",
    "with vision.ImageSegmenter.create_from_options(options) as segmenter:\n",
    "\n",
    "    # Loop through demo image(s)\n",
    "    for image_file_name in IMAGE_FILENAMES:\n",
    "\n",
    "        # Create the MediaPipe image file that will be segmented\n",
    "        image = mp.Image.create_from_file(image_file_name)\n",
    "\n",
    "        # Retrieve the masks for the segmented image\n",
    "        segmentation_result = segmenter.segment(image)\n",
    "        category_mask = segmentation_result.category_mask.numpy_view()\n",
    "\n",
    "        # Convert the original image to RGB for display\n",
    "        original_image = image.numpy_view()\n",
    "        if original_image.shape[-1] == 4:  # If RGBA, convert to RGB\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "        output_image = np.zeros_like(original_image, dtype=np.uint8)\n",
    "        output_image[:] = BG_COLOR  # Initialize with background color\n",
    "\n",
    "        # Overlay each class with its corresponding color\n",
    "        for class_id in range(len(MASK_COLORS)):\n",
    "            mask_color = np.array(MASK_COLORS[class_id], dtype=np.uint8)\n",
    "            class_mask = category_mask == class_id\n",
    "\n",
    "            # Create an overlay with the specific class color\n",
    "            overlay = np.zeros_like(output_image, dtype=np.uint8)\n",
    "            overlay[class_mask] = mask_color\n",
    "\n",
    "            # Blend the overlay with the output image\n",
    "            output_image = cv2.addWeighted(output_image, 1.0, overlay, 0.5, 0)\n",
    "\n",
    "        # Display the result\n",
    "        print(f\"Unique classes in {image_file_name}: {np.unique(category_mask)}\")\n",
    "        cv2.imshow(f\"Segmented Image with Highlighted Classes - {image_file_name}\", output_image)\n",
    "        cv2.waitKey(0)  # Wait for a key press before showing the next image\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
